{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77d000bb-8a35-4de6-ae29-1f8dd896a5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertTokenizerFast, BertForSequenceClassification, BertModel, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "# matplotlib.use('Qt5Agg')\n",
    "# import matplotlib.pyplot as plt\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import copy\n",
    "import math\n",
    "from tqdm import tqdm, trange\n",
    "from torch.nn import SyncBatchNorm\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "# import evaluate\n",
    "work_dir = \"./\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "542f3039-5093-4dcb-b602-a60be1170245",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50\")\n",
    "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07089412-04df-4c68-8bf0-f93e567dfc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/adminniu/.cache/huggingface/modules/datasets_modules/datasets/cnn_dailymail/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de (last modified on Fri Mar 10 11:32:23 2023) since it couldn't be found locally at cnn_dailymail., or remotely on the Hugging Face Hub.\n",
      "Found cached dataset cnn_dailymail (/home/adminniu/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48dd451ae26e4ffe97c3539ac5a8b40c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 287113\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 13368\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 11490\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"cnn_dailymail\", '3.0.0')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d22f57db-c5cf-436a-961f-a78b00ce5f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[250004,      6, 106699,  89539,      4,  30715,     15, 192619,     16,\n",
       "           4210,  20904,  59566,   6057,  11555,   9552, 195167,     13,  21647,\n",
       "              7,  17203,     47,     10, 113771,  11762,   1549,  19879,     15,\n",
       "           4369,    617,  92134,  19879,     16,    100,  45091,    237,    764,\n",
       "          15504,      7,    543,     98,  68318,      4,   1284,    764,  51636,\n",
       "              7,     70,  17265,  23742,     25,     18,  37702,     10, 160093,\n",
       "             98,   4049,      5,  11555,   9552, 195167,     13,    237,  20904,\n",
       "          59566,     23,     44,  30404,   1294,  59566,    136,     70,  81206,\n",
       "            111,     70, 133720,     58,    717,     70,   2837, 140545,    674,\n",
       "            111, 207039,   3365,    316,  42729,      7,  10932,     70,   8999,\n",
       "              4,     70,  27150,  39329,  17378,    764,   1556,    110,  38627,\n",
       "             47,  97613,     56,   1919,  49456,  16065,     98,   4271,   2258,\n",
       "              7,      4,  23417,    136, 211099,  68036,      5,     44,    568,\n",
       "           2301,     25,     18,   1774,     47,    186,   1632,    111,   8382,\n",
       "           3395,   2750,      4,    237,  33662,    237,   1836,  15504,    543,\n",
       "              4, 186683,  22113,  61261,     10, 106750,  29681,   2258,  42486,\n",
       "            707,   9844,  21373,      4,     58,    764,  30745,    142, 133836,\n",
       "          33683,     56, 110680,    903,  31150,      5,     44,    568,   2301,\n",
       "             25,     18,   5351,     87,     25,   1181,    186, 106480,   4173,\n",
       "            330,  71216,      5,     44,   3957,   8966,     87,   1884, 129004,\n",
       "            621,   8966,    450,  11034,   1672,    209, 194973,   4210,  42840,\n",
       "            136,   7915,      7,    136,  12352,      7,   1242,   1913,    543,\n",
       "              4,   9552, 195167,     13,   1221,    186,  19048,     47,    914,\n",
       "          40099,     23,     10,   8174,      4,  22113,     10,  23417,     23,\n",
       "             10,  64792,    707,   1957,     70,  92973,   1346,     44,  11193,\n",
       "           9235,     12,  16995,   1995,      4,     58,  82424,  37195,  44677,\n",
       "          35064,   1919,  14012,   1632,  14277,     98,     70,  17274,  16530,\n",
       "          23179, 116287,      5,  77658,    111,   3642,    764,     25,   1181,\n",
       "          16188,   1919,   3551,  10015, 101207,    621,   1379, 137565,      7,\n",
       "              5,  18763,  23882,    136, 201569,   1902,    110,   6868,     98,\n",
       "           1919,  38627,      5,     44,    568,     25,   1181,  58621,    765,\n",
       "           3060,  12096,    111,  19085,      4,     58,    764,   2804,     23,\n",
       "            142,  33683,      5,     44,  11193,   1081, 126351,    351,     13,\n",
       "            111,    398,   1221,    186,  16454,   1672,    442,   1242,   9552,\n",
       "         195167,     13,     25,      7,  85168,   5180,   1295,     70,   5117,\n",
       "          43606,  59566,  54180,    765,   2809,  34658,     23,     10,  63207,\n",
       "           9458,   3129,    764,   1556,    959,   2809,  19048,     47,  23996,\n",
       "              5,    262,  61518,   1919, 105925,  65536,    136, 118513,      7,\n",
       "              4,     70,  39329,  17378,    764,     83, 120260,   1919,  74261,\n",
       "          11037,    538,     98,     70,  61585,      5,     44, 243238,    621,\n",
       "          11343,  16487,     47,   5154,    242,  35953,   6057,  60899,   5773,\n",
       "             70,    673,   7870,      4,     25,     58,    764,  30745, 105757,\n",
       "              7,   4568,  31150,      5,     44,  82212,     87,   9790,   4552,\n",
       "           7941,    959,     47,    738,    450,   3917,   6637,    442,   2806,\n",
       "            186,   5792,  23468,    100,   2856,   1242,  18763,  42850,   1810,\n",
       "            214,    237,     70,  25299,    148,  14821,     71,     23,     44,\n",
       "          30404,   1294,  59566,    136,     70,  81206,    111,     70, 133720,\n",
       "             58,     83, 116987, 115923,     98,  15044,   5609,      7,    111,\n",
       "             70, 142740,    136,    764,   1221, 158323,     70,  31486,     23,\n",
       "             70,   4568,   6626,  54180,      5,  20413,     87,      9,  56829,\n",
       "             56,   8337,    604,   8347,    111,  59566,     25,      7,  42850,\n",
       "            340,      6,      5,   8622,     83,   6897, 107314,  59566,      4,\n",
       "          49903,      5,    581,   9020,     56,   1556,   1346,    297,     10,\n",
       "           1910,  14277,  35839,     44,  31852,  29642,  21763,      4,     58,\n",
       "           1672,  42179,  42926, 119300, 106642,   2069,    136,   1919,    775,\n",
       "              4,   4743,    100,  54452,  14432,    903,   6602,      5,   1529,\n",
       "           1221,   2843, 108975,     23,     44, 120152,  27417, 112860,      4,\n",
       "             58,    142, 133836,   1346,   1672,  22759, 115982,   2750, 144281,\n",
       "            142,    707,  68743,   4588,      5,    241,    147,  56786,    903,\n",
       "           6602,      4,    764,   7228,   1919,  36541,  34377,  75169,     10,\n",
       "         134357,    297, 166513,     23,   7948,   7224,  18234,     25,      7,\n",
       "             44,    647,   5490,    223,   1242,   1215,     66, 204610,      4,\n",
       "            764,     83,   1620,  37534,    100,   3853,  20903,     42,   2450,\n",
       "         199178,     53,   5036,    450,    764,     25,      7,   8437,    538,\n",
       "            142,  25171,     12,     44,    568,   1660,   5351,     87,     25,\n",
       "             39,   7730,     47,    186,   1286,  12096,    111,  44075,   6712,\n",
       "              4,     58,    764,  30745,  41325,      5,    241,      9,   2065,\n",
       "             47,     10,  34391,      6,      5,   4189,   2691,  41325,      5,\n",
       "           3164,  38109,  70488,      5,  73243,   4912,   1543,    959,    186,\n",
       "          91376,      4, 226347,      4,    456,   5429,  75639,      4,    707,\n",
       "         242564,   3674,      5,      2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tokenizer(dataset[\"train\"][0][\"article\"], return_tensors=\"pt\")\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1472da9-5ffa-486b-9660-354431b98d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adminniu/anaconda3/envs/lhr/lib/python3.7/site-packages/transformers/generation/utils.py:1278: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 200 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[     2,      0,  11555,   9552, 195167,     13,    237,  20904,  59566,\n",
       "             23,     44,  30404,   1294,  59566,    136,     70,  81206,    111,\n",
       "             70, 133720,     58,      2]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model.generate(**input_ids)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a85ea447-cfd6-4e4d-aa4d-262ac0c428fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\"'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "97d15a8b-6c22-4931-98a5-e7b4f8070bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don't plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don't think I'll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how he'll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I'll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffe's earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say 'kid star goes off the rails,'\" he told reporters last month. \"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films.  Watch I-Reporter give her review of Potter's latest » . There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December Boys,\" an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer's \"Equus.\" Meanwhile, he is braced for even closer media scrutiny now that he's legally an adult: \"I just think I'm going to be more sort of fair game,\" he told Reuters. E-mail to a friend . Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed.\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"][0][\"article\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10ad4ac8-f9cf-4d51-b000-db54d811a2aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'shift_tokens_right' from 'transformers.models.bart' (/home/adminniu/anaconda3/envs/lhr/lib/python3.7/site-packages/transformers/models/bart/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29942/614957719.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBartTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBartForConditionalGeneration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbart\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshift_tokens_right\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'shift_tokens_right' from 'transformers.models.bart' (/home/adminniu/anaconda3/envs/lhr/lib/python3.7/site-packages/transformers/models/bart/__init__.py)"
     ]
    }
   ],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.models.bart import shift_tokens_right\n",
    "\n",
    "\n",
    "def convert_to_features(example_batch):\n",
    "    input_encodings = tokenizer.batch_encode_plus(example_batch['text'], pad_to_max_length=True, max_length=1024, truncation=True)\n",
    "    target_encodings = tokenizer.batch_encode_plus(example_batch['summary'], pad_to_max_length=True, max_length=1024, truncation=True)\n",
    "    \n",
    "    labels = target_encodings['input_ids']\n",
    "    decoder_input_ids = shift_tokens_right(labels, model.config.pad_token_id)\n",
    "    labels[labels[:, :] == model.config.pad_token_id] = -100\n",
    "    \n",
    "    encodings = {\n",
    "        'input_ids': input_encodings['input_ids'],\n",
    "        'attention_mask': input_encodings['attention_mask'],\n",
    "        'decoder_input_ids': decoder_input_ids,\n",
    "        'labels': labels,\n",
    "    }\n",
    "\n",
    "    return encodings\n",
    "\n",
    "dataset = dataset.map(convert_to_features, batched=True)\n",
    "columns = ['input_ids', 'labels', 'decoder_input_ids','attention_mask',] \n",
    "dataset.set_format(type='torch', columns=columns)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./models/bart-summarizer',          \n",
    "    num_train_epochs=1,           \n",
    "    per_device_train_batch_size=1, \n",
    "    per_device_eval_batch_size=1,   \n",
    "    warmup_steps=500,               \n",
    "    weight_decay=0.01,              \n",
    "    logging_dir='./logs',          \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                       \n",
    "    args=training_args,                  \n",
    "    train_dataset=dataset['train'],        \n",
    "    eval_dataset=dataset['validation']   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "171514d2-f1de-40ef-9212-d96a80c49f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Downloader\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Downloader>  l\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Packages:\n",
      "Error connecting to server: [Errno 111] Connection refused\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29942/4096719029.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/lhr/lib/python3.7/site-packages/nltk/downloader.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, info_or_id, download_dir, quiet, force, prefix, halt_on_error, raise_on_error, print_error_to)\u001b[0m\n\u001b[1;32m    761\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdownload_dir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interactive_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lhr/lib/python3.7/site-packages/nltk/downloader.py\u001b[0m in \u001b[0;36m_interactive_download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1113\u001b[0m                 \u001b[0mDownloaderGUI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTclError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m                 \u001b[0mDownloaderShell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m             \u001b[0mDownloaderShell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lhr/lib/python3.7/site-packages/nltk/downloader.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1139\u001b[0m                 \u001b[0;34m\"q) Quit\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m             )\n\u001b[0;32m-> 1141\u001b[0;31m             \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Downloader> \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lhr/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m         )\n\u001b[1;32m   1183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lhr/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "498183cb-3800-4f16-8b4b-fa99beddbe34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileSystemPathPointer('/home/adminniu/nltk_data/tokenizers/punkt/PY3')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.data.find(\"tokenizers/punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db4230c-5bc2-4736-93bc-9968d1e934e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lhr] *",
   "language": "python",
   "name": "conda-env-lhr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
